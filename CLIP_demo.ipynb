{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "# import clip\n",
    "import open_clip\n",
    "import json\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as tvt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from contextlib import suppress\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, root, transform, json_path):\n",
    "        self.root = root\n",
    "        new_class_list = []\n",
    "        class_indices = {}\n",
    "        for cla in os.listdir(self.root):\n",
    "            new_class_list.append(cla)\n",
    "        for i, cla in enumerate(new_class_list):\n",
    "            class_indices[str(i)] = cla\n",
    "        if json_path:\n",
    "            with open(json_path, \"w\") as json_file:\n",
    "                json.dump(class_indices, json_file)\n",
    "        self.class_list = new_class_list\n",
    "        self.transform = transform\n",
    "\n",
    "        self.path_list = []  # a list of image paths\n",
    "        self.img_list = []   # a list of images paths with corresponding labels\n",
    "\n",
    "        for file in self.class_list:\n",
    "            file_path = os.path.join(self.root, file, \"\")\n",
    "            self.path_list.append(file_path)\n",
    "            file_label = self.class_list.index(file)\n",
    "            pattern = file_path + '*'\n",
    "            for img in glob.glob(pattern):\n",
    "                img_list = [file_label, img]\n",
    "                # add image label and path to a image list\n",
    "                self.img_list.append(img_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_label = self.img_list[index][0]\n",
    "        img = Image.open(self.img_list[index][1])\n",
    "        img_transformed = self.transform(img)\n",
    "        return img_transformed, img_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrix(object):\n",
    "\n",
    "\n",
    "    def __init__(self, num_classes: int, labels: list):\n",
    "        self.matrix = np.zeros((num_classes, num_classes))\n",
    "        self.num_classes = num_classes\n",
    "        # label_list = []\n",
    "        # for i, label in enumerate(labels):\n",
    "        #     if i%3 == 0:\n",
    "        #         label_list.append(label)\n",
    "\n",
    "        self.labels = labels\n",
    "\n",
    "    def update(self, preds, labels):\n",
    "        # add the result of each iteration\n",
    "        for p, t in zip(preds, labels):\n",
    "            self.matrix[p//3, t] += 1\n",
    "\n",
    "\n",
    "    def summary(self):\n",
    "        # calculate accuracy\n",
    "        sum_TP = 0\n",
    "        n = np.sum(self.matrix)\n",
    "        for i in range(self.num_classes):\n",
    "            sum_TP += self.matrix[i, i]\n",
    "        acc = sum_TP / n\n",
    "        print(\"the model accuracy is \", acc)\n",
    "        return str(acc)\n",
    "\n",
    "    def plot(self):\n",
    "        matrix = self.matrix\n",
    "        # df = pd.DataFrame(matrix, columns=self.labels, index=self.labels)\n",
    "        # df.to_csv(\"cm_aid.cvs\")\n",
    "        print(matrix)\n",
    "        plt.figure(figsize=(18, 14))\n",
    "        plt.imshow(matrix, cmap=plt.cm.Blues)\n",
    "\n",
    "     \n",
    "        plt.xticks(range(self.num_classes), self.labels, rotation=90)\n",
    "        plt.yticks(range(self.num_classes), self.labels)\n",
    "        #colorbar\n",
    "        plt.colorbar()\n",
    "        plt.xlabel('True Labels')\n",
    "        plt.ylabel('Predicted Labels')\n",
    "        plt.title('Confusion matrix (acc='+self.summary()+')')\n",
    "\n",
    "        #annotation\n",
    "        thresh = matrix.max() / 2\n",
    "        for x in range(self.num_classes):\n",
    "            for y in range(self.num_classes):\n",
    "                info = int(matrix[y, x])\n",
    "                plt.text(x, y, info,\n",
    "                         verticalalignment='center',\n",
    "                         horizontalalignment='center',\n",
    "                         color=\"white\" if info > thresh else \"black\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"patternnet_confusion_matrix.jpg\", dpi=300)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from https://github.com/LAION-AI/CLIP_benchmark/blob/main/clip_benchmark/metrics/zeroshot_classification.py\n",
    "\n",
    "def zero_shot_classifier(model, tokenizer, classnames, templates, prompts, device, amp=True, cupl=False):\n",
    "\n",
    "    autocast = torch.cuda.amp.autocast if amp else suppress\n",
    "    with torch.no_grad(), autocast():\n",
    "        zeroshot_weights = []\n",
    "        for classname in tqdm(prompts.keys()):\n",
    "            if cupl:\n",
    "                texts = templates[classname]\n",
    "            else:\n",
    "                texts = [template.format(c=classname) for template in templates]\n",
    "            texts = tokenizer(texts).to(device)  # tokenize\n",
    "            class_embeddings = model.encode_text(texts)\n",
    "            class_embedding = F.normalize(class_embeddings, dim=-1).mean(dim=0)\n",
    "            class_embedding /= class_embedding.norm()\n",
    "            zeroshot_weights.append(class_embedding)\n",
    "        zeroshot_weights = torch.stack(zeroshot_weights, dim=1).to(device)\n",
    "    return zeroshot_weights\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    pred = output.topk(max(topk), 1, True, True)[1].t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    n = len(target)\n",
    "    return [float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy())/ n for k in topk]\n",
    "\n",
    "    \n",
    "\n",
    "def run(model, classifier, dataloader, class_num, class_indices, device, amp = True):\n",
    "    autocast = torch.cuda.amp.autocast if amp else suppress\n",
    "    labels = [label for _,label in class_indices.items()]\n",
    "    confusion = ConfusionMatrix(num_classes=class_num, labels=labels)\n",
    "    pred = []\n",
    "    groundTruth = []\n",
    "    nb = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        top1, top5, n = 0., 0., 0.\n",
    "        for images, target in tqdm(dataloader):\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            with autocast():\n",
    "                # predict\n",
    "                image_features = model.encode_image(images)\n",
    "                image_features = F.normalize(image_features, dim=-1)\n",
    "                logits = (100. * image_features @ classifier)\n",
    "\n",
    "            \n",
    "            groundTruth.append(target.cpu())\n",
    "            pred.append(logits.float().cpu())\n",
    "            pred1 = logits.topk(1, 1, True, True)[1].t()\n",
    "            confusion.update(pred1.to(\"cpu\").numpy(), target.to(\"cpu\").numpy())\n",
    "    \n",
    "    pred = torch.cat(pred)\n",
    "    true = torch.cat(groundTruth)\n",
    "    confusion.plot() \n",
    "    return pred, true\n",
    "\n",
    "\n",
    "def average_precision_per_class(scores, targets):\n",
    "\n",
    "    ap = torch.zeros(scores.size(1))\n",
    "    rg = torch.arange(1, scores.size(0) + 1).float()\n",
    "    # compute average precision for each class\n",
    "    for k in range(scores.size(1)):\n",
    "        # sort scores\n",
    "        scores_k = scores[:, k]\n",
    "        targets_k = targets[:, k]\n",
    "        _, sortind = torch.sort(scores_k, 0, True)\n",
    "        truth = targets_k[sortind]\n",
    "        tp = truth.float().cumsum(0)\n",
    "        # compute precision curve\n",
    "        precision = tp.div(rg)\n",
    "        # compute average precision\n",
    "        ap[k] = precision[truth.bool()].sum() / max(float(truth.sum()), 1)\n",
    "    return ap\n",
    "\n",
    "def evaluate(model, dataloader, tokenizer, classnames, templates, prompts, class_indices, device, amp=True, verbose=False, cupl=False, save_clf=None, load_clfs=[]):\n",
    "    \n",
    "    labels = [label for _,label in class_indices.items()]\n",
    "    confusion = ConfusionMatrix(num_classes=len(classnames), labels=labels)\n",
    "    if len(load_clfs) > 0:\n",
    "        n = len(load_clfs)\n",
    "        classifier = torch.load(load_clfs[0], map_location='cpu') / n\n",
    "        for i in range(1, n):\n",
    "            classifier = classifier + torch.load(load_clfs[i], map_location='cpu') / n\n",
    "        classifier = classifier.to(device)\n",
    "    else:\n",
    "        classifier = zero_shot_classifier(model, tokenizer, classnames, templates, prompts, device, cupl=cupl)\n",
    "    \n",
    "    if save_clf is not None:\n",
    "        torch.save(classifier, save_clf)\n",
    "        # exit() - not sure if we want to exit here or not.\n",
    "    class_num = len(classnames)\n",
    "    logits, target = run(model, classifier, dataloader, class_num, class_indices, device, amp=amp)\n",
    "    is_multilabel = (len(target.shape) == 2)\n",
    "\n",
    "    if is_multilabel:\n",
    "        if verbose:\n",
    "            print(\"Detected a multi-label classification dataset\")\n",
    "        # Multiple labels per image, multiple classes on the dataset\n",
    "        ap_per_class = average_precision_per_class(logits, target)\n",
    "        if verbose:\n",
    "            for class_name, ap in zip(classnames, ap_per_class.tolist()):\n",
    "                print(f\"Class: {class_name}, AveragePrecision: {ap}\")\n",
    "        return {\"mean_average_precision\": ap_per_class.mean().item()}\n",
    "    else:\n",
    "        # Single label per image, multiple classes on the dataset\n",
    "        # just compute accuracy and mean_per_class_recall\n",
    "\n",
    "        pred = logits.argmax(axis=1)\n",
    "\n",
    "        # measure accuracy\n",
    "        if len(classnames) >= 3:\n",
    "            acc1, acc5 = accuracy(logits, target, topk=(1, 3))\n",
    "        else:\n",
    "            acc1, = accuracy(logits, target, topk=(1,))\n",
    "            acc5 = float(\"nan\") \n",
    "        mean_per_class_recall = balanced_accuracy_score(target, pred)\n",
    "        if verbose:\n",
    "            print(classification_report(target, pred, digits=3))\n",
    "        return {\"acc1\": acc1, \"acc3\": acc5, \"mean_per_class_recall\": mean_per_class_recall}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='openai')\n",
    "# model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n",
    "model.to(device)\n",
    "tokenizer = open_clip.get_tokenizer('ViT-B-32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prompts map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_to_parent = {\n",
    "    \"AIRPORT: A large, open field with a runway in the middle. The field is covered with grass, and there are airplanes parked on the runway. There is a terminal in the background.\" : \"airport\",\n",
    "    \"AIRPORT:The land cover in this picture is an airport, specifically an airport runway and surrounding area. The scene provides a comprehensive view of the airport's layout and infrastructure, including the runway, taxiways, and terminal building.\": \"airport\",\n",
    "    \"AIRPORT:the image shows a large grassy field with a runway in the middle, surrounded by a variety of airplanes parked on the runway. The presence of multiple airplanes parked on the runway indicates that the airport is active and in use.\": \"airport\",\n",
    "    \"BARELAND: A dry and barren landscape with little vegetation. It appears to be a rough terrain.\" : \"bareland\",\n",
    "    \"BARELAND: The image shows a large, empty lot with dirt and debris.\" : \"bareland\",\n",
    "    \"BARELAND: A construction site, which is an area where buildings or structures are being built or renovated. The image shows a large, open area with dirt and sand.\" : \"bareland\",\n",
    "    \"BASEBALL FIELD: The image shows a large, grassy field with a baseball diamond in the center, surrounded by a dirt infield and a grass outfield.\" : \"baseball field\",\n",
    "    \"BASEBALL FIELD: The image shows a baseball field with a large circular infield, surrounded by a grassy outfield.\" : \"baseball field\",\n",
    "    \"BASEBALL FIELD: The image shows a large grassy field with several baseball diamonds, each with a home plate, bases, and a pitcher's mound.\" : \"baseball field\",\n",
    "    \"BEACH: The beach is surrounded by water, and there is a sandy area with a large sand dune on the coast.\" : \"beach\",\n",
    "    \"BEACH: The land cover in the image is a beach with sand and water. The beach is covered in sand, and there is a body of water, likely an ocean.\" : \"beach\",\n",
    "    \"BEACH: The land cover in this picture is a sandy beach with a sandy dune area.\" : \"beach\",\n",
    "    \"BRIDGE: The land cover type in this picture is a bridge, that looks like a curved gray-line in the image.\" : \"bridge\",\n",
    "    \"BRIDGE: The land cover is a bridge crossing over water. There are also people on the bridge.\" : \"bridge\",\n",
    "    \"BRIDGE: The bridge is connecting two lands crossing the water.\" : \"bridge\",\n",
    "    \"CENTER: There is a large, modern building, which appears to be a white, and looks like a center.\" : \"center\",\n",
    "    \"CENTER: There is a large, circular building surrounded by grass and trees. The building appears to be a large, modern structure that coould be a center.\" : \"center\",\n",
    "    \"CENTER: A white irregular-shaped building is in the middle of the image. It is situated in an urban area.\" : \"center\",\n",
    "    \"CHURCH: There is a white and gray Christian churches built in a cross-shaped architectural style.\": \"church\",\n",
    "    \"CHURCH: A irregular-shaped white building is situated in the middle of the picture. \" : \"church\",\n",
    "    \"CHURCH: There is a cruciform-shaped church that has a orange roof in the middle of the image surronded by other orange buildings.\" : \"church\",\n",
    "    \"COMMERCIAL: The image shows a bird's-eye view of a city, with a large number of buildings and roads, as well as a few parking lots.\" : \"commercial\",\n",
    "    \"COMMERCIAL: There are many cars on the roads and a significant number of buildings visible. The cityscape is likely filled with various types of buildings, including commercial, and office spaces, as well as public spaces like parks and plazas.\" : \"commercial\",\n",
    "    \"COMMERCIAL: The content of the picture includes various buildings, such as hotels, office buildings, and commercial structures, as well as roads and possibly a body of water, which could be a lake or a river.\" : \"commercial\",\n",
    "    \"DENSE RESDENTIAL: The view is characterized by a dense network of streets, buildings, and various structures. There are numerous houses and apartments and a significant amount of urban development.\" : \"dense resdential\",\n",
    "    \"DENSE RESDENTIAL: It is a dense neighborhood with a large number of houses. there are also cars parked on the street. The houses are of various colors, including brown, white, and gray, and they are arranged in a grid-like pattern.\" : \"dense resdential\",\n",
    "    \"DENSE RESDENTIAL: The area is filled with multiple buildings, including apartments and houses. There are also cars and a pedestrian crossing in the scene. The content of the picture is focused on the urban environment, highlighting the density and diversity of the cityscape.\" : \"dense resdential\",\n",
    "    \"DESERT: The image features a sandy beach and the sand dunes are visible in the distance.\" :\"desert\",\n",
    "    \"DESERT: The view is a sandy desert, with a sandy surface and some rocky formations. The image shows a close-up view of the sandy desert, which is characterized by its sandy texture and rocky features.\" :\"desert\",\n",
    "    \"DESERT: The image shows a sandy desert, with a sandy texture and a sandy color.\" :\"desert\",\n",
    "    \"FARMLAND: The is a large, flat, and open field. The field is covered with crops and has a few trees scattered throughout.\" : \"farmland\",\n",
    "    \"FARMLAND: There is a large field with a river running through it. The field is covered with crops and green vegetations.\" : \"farmland\",\n",
    "    \"FARMLAND: There is a large, flat area of land used for agricultural purposes. The field is covered with green vegetation, which could be crops, or other types of plants.\" : \"farmland\",\n",
    "    \"FOREST: There is a dense forest, with a mix of trees and greenery. The image shows a close-up view of the forest, with a lot of trees and foliage, creating a lush and vibrant landscape.\" : \"forest\",\n",
    "    \"FOREST: The image shows a large area of forest, with a lot of trees and foliage, creating a lush and vibrant landscape.\" : \"forest\",\n",
    "    \"FOREST: The image shows a dense forest, consisting of a large area of trees. The forest is covered in green foliage, which indicates that it is likely a lush and healthy ecosystem.\" : \"forest\",\n",
    "    \"INDUSTRIAL: There is a large industrial area, with numerous buildings and warehouses. The image shows a city with a significant amount of commercial and industrial activity, as evidenced by the numerous shipping containers and large buildings.\" : \"industrial\",\n",
    "    \"INDUSTRIAL: The image shows a cityscape with a variety of buildings, including office buildings, factories, and warehouses.\" : \"industrial\",\n",
    "    \"INDUSTRIAL: It is an industrial area, with multiple factories and buildings visible. The content of the image includes various types of factories, warehouses, and other industrial structures.\" : \"industrial\",\n",
    "    \"MEADOW: It is a field of green grass. The image shows a large expanse of green grass. The grass is well-maintained and appears to be healthy.\" : \"meadow\",\n",
    "    \"MEADOW: The view is a large, open field of grass. The meadow is covered with dirt and has some dirt roads running through it.\" : \"meadow\",\n",
    "    \"MEADOW: The view in the image is a large, open field with grass.\" : \"meadow\",\n",
    "    \"MEADIUM RESDENTIAL: The image shows a close-up view of a street with some houses, some of which are red and some are brown. The houses are situated in a row, and there are trees in the background.\" : \"medium resdential\",\n",
    "    \"MEADIUM RESDENTIAL: The image shows a colse view of the residential area, which is a neighborhood with not much people. The houses are arranged in a grid-like pattern, with a few roads and sidewalks connecting them.\" : \"medium resdential\",\n",
    "    \"MEADIUM RESDENTIAL: The image shows a close view of neighborhood with few houses and buildings, as well as a park or green area. The overall content of the picture is a medium residential neighborhood.\" : \"medium resdential\",\n",
    "    \"MOUNTAIN: The image shows a mountainous terrain with a mix of green and brown colors. The mountainous terrain is covered with a variety of vegetation, including grass and trees, which gives it a lush and vibrant appearance.\" : \"mountain\",\n",
    "    \"MOUNTAIN: The view in this picture is a mountainous terrain with snow-covered peaks and valleys. The image features a large mountain range, which is covered in snow, and the landscape appears to be quite rugged and rocky.\" : \"mountain\",\n",
    "    \"MOUNTAIN: The view in the image is a mountainous terrain, with a large expanse of greenery covering the hills and valleys. The landscape features a mix of grassy hills and rocky outcrops, creating a diverse and visually appealing scene.\" : \"mountain\",\n",
    "    \"PARK: It is a park or a recreational area, featuring a large lake, a road, and a pathway. The park is designed with a complex network of roads and paths, which are likely intended for various recreational activities such as walking, jogging, or cycling.\" : \"park\",\n",
    "    \"PARK: The view in the image is a large park or amusement park, featuring a variety of water-based attractions, such as water slides, a water park, and a swimming pool. The park is surrounded by a city, and there are also some trees in the area.\" : \"park\",\n",
    "    \"PARK: The picture shows a park, with a playground. The image shows a bird's-eye view of the park, which is surrounded by buildings and a city. The park is a green space with a playground, and possibly other recreational facilities.\" : \"park\",\n",
    "    \"PARKING: The image shows a large parking lot with many cars parked in rows, creating a grid-like pattern. The parking lot is surrounded by buildings.\" : \"parking\",\n",
    "    \"PARKING: The content of the image shows a large parking lot filled with cars, with some empty spaces available. The parking lot is surrounded by buildings and other structures.\" : \"parking\",\n",
    "    \"PARKING: The scene is captured from an aerial view, giving a bird's-eye perspective of the parking lot and the vehicles parked within it.\" : \"parking\",\n",
    "    \"PLAYGROUND: The image shows a large, green soccer field with a red track surrounding it, which is likely a running track.\" : \"playground\",\n",
    "    \"PLAYGROUND: The image shows a large soccer field with trees in the background, and there are people playing soccer on the field.\" : \"playground\",\n",
    "    \"PLAYGROUND: The image shows a large, flat, and open area designed for playing soccer. The field is covered in grass, and it is surrounded by a fence, which is likely to be used for marking the boundaries of the field.\" : \"playground\",\n",
    "    \"POND: The image shows a large, open area with a pond in the center, surrounded by dirt and rocks.\" : \"pond\",\n",
    "    \"POND: The image depicts a serene and picturesque scene with a lake in the center, surrounded by dirt and rocks. The lake is situated in the middle of an open area. The area might be a park or a recreational area.\" : \"pond\",\n",
    "    \"POND: There is a large body of water, which appears to be a lake. The image shows a lake with a large hole in the middle, surrounded by grassy land.\" : \"pond\",\n",
    "    \"PORT: The image shows a harbor or docking area for boats and ships. There is a large body of water with boats docked in the marina, and there are also buildings and structures in the area.\" : \"port\",\n",
    "    \"PORT: The view in this picture is a body of water, specifically a large body of water with boats docked along the shore. The marina is surrounded by a city.\" : \"port\",\n",
    "    \"PORT: The content of the image shows a large marina with many boats docked in it. The boats are parked in a circular pattern.\" : \"port\",\n",
    "    \"RAILWAY STATION: The image shows a large, open area with a railway station in the center. The railway station is surrounded by a mix of residential and industrial buildings.\" : \"railway station\",\n",
    "    \"RAILWAY STATION: The image shows a large area with multiple train tracks, which are surrounded by buildings and other structures.\" : \"railway station\",\n",
    "    \"RAILWAY STATION: The image shows a map of the rail yard, with multiple train tracks and a variety of buildings, including a large warehouse.\" : \"railway station\",\n",
    "    \"RESORT: The image shows a view of the city from above, with a building that has a pool on its rooftop. The pool is surrounded by a deck and appears to be a popular spot for relaxation and leisure.\" : \"resort\",\n",
    "    \"RESORT: The image shows a large hotel complex, which is surrounded by a lush green lawn and a sandy beach. The hotel has a pool, which is visible in the image. The beach is also visible, with sand and water in the foreground.\" : \"resort\",\n",
    "    \"RESORT: There is a large, luxurious complex with multiple buildings, a lake, and a golf course. The resort is surrounded by a forest, which adds to its natural beauty and serene atmosphere.\" : \"resort\",\n",
    "    \"RIVER: It is a river with a sandy beach and some trees nearby. The river is flowing through a forest, and there is a small village or town visible in the background.\" : \"river\",\n",
    "    \"RIVER: The river is surronded by a grassy field. The image also shows a city or town in the background.\" : \"river\",\n",
    "    \"RIVER: The river is flowing through a lush, green forest, which is a common characteristic of tropical rainforests. The image shows the river's winding path, with sandy banks and a sandy bottom. The forest is dense and full of trees.\" : \"river\",\n",
    "    \"SCHOOL: It is a campus or university area. The image shows a large, open area with buildings, including a few tall buildings, and a grassy field. There are also trees scattered throughout the area.\" : \"school\",\n",
    "    \"SCHOOL: The school area is likely a campus or a neighborhood with multiple schools, as there are multiple buildings visible in the picture and various and green spaces visible.\" : \"school\",\n",
    "    \"SCHOOL: The image shows a school with a large field in the middle of it. The school is surrounded by buildings, and there is a stadium in the middle of the field. The image also shows a road and a parking lot.\" : \"school\",\n",
    "    \"SPARSE RESDENTIAL: There is only one house in the neighborhood surronded by some trees and green vegetation.\" : \"sparse resdential\",\n",
    "    \"SPARSE RESDENTIAL: The image shows a large area withone house situated in the middle of it.\" : \"sparse resdential\",\n",
    "    \"SPARSE RESDENTIAL: The image shows a bird's-eye view of the neighborhood, with only one house and a pool situated in the middle of the property.\" : \"sparse resdential\",\n",
    "    \"SQUARE: The image shows a large open space with a dirt circle in the center, surrounded by various construction equipment and vehicles.\" : \"square\",\n",
    "    \"SQUARE: The image shows a large open space with trees and a grassy area. The area is filled with trees, and there is a large grassy area in the center.\" : \"square\",\n",
    "    \"SQUARE: The view in this picture is a large, open park with a square in the center. The park is surrounded by buildings, and there are people enjoying the outdoor space.\" : \"square\",\n",
    "    \"STADIUM: The view in the image is a large, circular stadium with a grass field. The stadium is surrounded by a parking lot and a road, indicating that it is likely a sports facility.\" : \"stadium\",\n",
    "    \"STADIUM: The land cover in this picture is a large, open field or stadium, which is covered in green grass.\" : \"stadium\",\n",
    "    \"STADIUM: The image shows a large, grassy field with a baseball diamond in the center, surrounded by a stadium with seating areas for spectators.\" : \"stadium\",\n",
    "    \"STORAGE TANKS: The image shows a large industrial complex with multiple tanks and a railroad track running alongside it.\" : \"storage tanks\",\n",
    "    \"STORAGE TANKS: The view in this picture is an industrial area, specifically a petrochemical plant or refinery. The image shows a large number of large tanks, which are likely used for storing and processing various types of petroleum products.\"  : \"storage tanks\",\n",
    "    \"STORAGE TANKS: The view in this picture is industrial, with a large complex of buildings and structures, including oil refineries, pipelines, and storage tanks.\" : \"storage tanks\",\n",
    "    \"VIADUCT: The image shows a large intersection with multiple roads and highways.\" : \"viaduct\",\n",
    "    \"VIADUCT: The image shows a close-up view of a city intersection, with multiple roads and traffic lights.\" : \"viaduct\",\n",
    "    \"VIADUCT: The view in this picture is a highway, specifically a complex interchange with multiple roads and ramps. The image shows a large, busy highway with multiple lanes and interchanges.\" : \"viaduct\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 'F:/course/2023summer/AID_val'\n",
    "batch_size = 1\n",
    "test_set = MyDataset(root = val ,transform = preprocess, json_path = 'aid.json')\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size,shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = [\"an aerial photo of the {c}.\", \n",
    "             \"an aerial photo of a {c}.\",\n",
    "             \"an aerial photo of an {c}.\",\n",
    "             \"an aerial photo of {c}.\"\n",
    "             ]\n",
    "with open(\"aid_classes_indices.json\", \"r\") as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "classnames = list(json_data.values())\n",
    "print(classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate(model = model, dataloader = test_loader, tokenizer = tokenizer, classnames = classnames, templates = templates, prompts = map_to_parent, class_indices=json_data, device = device, amp=True, verbose=False, cupl=False, save_clf=None, load_clfs=[])\n",
    "# dump = {\n",
    "#     \"dataset\": \"AID\",\n",
    "#     \"model\": \"ViT-B-32\",\n",
    "#     \"pretrained\": \"openai\",\n",
    "#     \"metrics\" : metrics,\n",
    "# }\n",
    "# with open(\"AID_results_hierarchy.json\", \"w\") as f:\n",
    "#         json.dump(dump, f)\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece60146",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
